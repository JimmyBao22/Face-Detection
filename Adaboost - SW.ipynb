{"cells":[{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1633,"status":"ok","timestamp":1701833844035,"user":{"displayName":"Jimmy Bao","userId":"13681281117205352536"},"user_tz":360},"id":"xwdbRl_EzR83","outputId":"df0d1f9d-29d6-4192-cf6f-2ec0c0e7a40e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"TZxWOUUezlCI"},"outputs":[],"source":["import cv2\n","import numpy as np\n","import random\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_recall_curve, accuracy_score\n","import os\n","from sklearn.utils import shuffle\n","import time\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import optimizers\n","\n","def cotan(angle):\n","    return -np.tan(angle + np.pi/2)\n","\n","# Function to convert ellipse to rectangular box\n","def ellipse_to_rectangle(major_axis, minor_axis, angle, center_x, center_y):\n","    t1 = np.arctan(-minor_axis * np.tan(angle) / major_axis)\n","    t2 = np.arctan(minor_axis * cotan(angle) / major_axis)\n","    xoff = abs(major_axis * np.cos(t1) * np.cos(angle) - minor_axis * np.sin(t1) * np.sin(angle))\n","    yoff = abs(minor_axis * np.sin(t2) * np.cos(angle) - major_axis * np.cos(t2) * np.sin(angle))\n","    x1 = center_x - xoff\n","    y1 = center_y - yoff\n","    x2 = center_x + xoff\n","    y2 = center_y + yoff\n","    return [x1, y1, x2, y2]\n","\n","def get_image(image_path, scale=6):\n","    image = cv2.imread(image_path)\n","    new_height = int(image.shape[0] / scale)\n","    new_width = int(image.shape[1] / scale)\n","    return cv2.resize(image, (new_width, new_height))\n","\n","# Parse FDDB dataset files and convert ellipse annotations to rectangles.\n","# Split into training and testing datasets.\n","def parse_fddb_dataset(folder_path, num_training=8):\n","    training_data = []\n","    testing_data = []\n","\n","    for i in range(1, 11):\n","        file_path = os.path.join(folder_path, f'FDDB-fold-{i:02}-ellipseList.txt')\n","        with open(file_path, 'r') as file:\n","            lines = file.readlines()\n","\n","        current_image = None\n","        face_count = 0\n","        get_face_count = False\n","        for line in lines:\n","            if get_face_count:\n","                face_count = int(line.strip())\n","                get_face_count = False\n","            elif face_count == 0:\n","                if current_image is not None:\n","                    # Process previous image\n","                    if i <= num_training:\n","                        training_data.append((current_image, faces))\n","                    else:\n","                        testing_data.append((current_image, faces))\n","\n","                current_image = os.path.join('/content/drive/MyDrive/Colab Notebooks/CV_dataset/originalPics/', line.strip() + '.jpg')\n","                faces = []\n","                get_face_count = True\n","            else:\n","                parts = [float(part) for part in line.split()]\n","                rect = ellipse_to_rectangle(*parts[:5])\n","                faces.append(rect)\n","                face_count -= 1\n","\n","        # Process the last image\n","        if current_image is not None:\n","            if i <= num_training:\n","                training_data.append((current_image, faces))\n","            else:\n","                testing_data.append((current_image, faces))\n","\n","    return training_data, testing_data\n","\n","def calculate_iou(boxA, boxB):\n","    # Determine the coordinates of the intersection rectangle\n","    xA = max(boxA[0], boxB[0])\n","    yA = max(boxA[1], boxB[1])\n","    xB = min(boxA[2], boxB[2])\n","    yB = min(boxA[3], boxB[3])\n","\n","    # Compute the area of intersection\n","    intersection_area = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n","\n","    # Compute the area of both bounding boxes\n","    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n","    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n","\n","    # Compute the intersection over union\n","    iou = intersection_area / float(boxAArea + boxBArea - intersection_area)\n","    return iou\n","\n","def sliding_window(image, step_size, window_size):\n","    for x in range(0, image.shape[1], step_size):\n","        for y in range(0, image.shape[0], step_size):\n","            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])\n","\n","def generate_samples_using_sliding_window(image, faces, window_size, step_size, iou_threshold, scale=6):\n","    positive_samples = []\n","    negative_samples = []\n","\n","    for (x, y, window) in sliding_window(image, step_size, window_size):\n","        # if window.shape[0] != window_size[1] or window.shape[1] != window_size[0]:\n","        #     continue\n","\n","        scaled_box = [x * scale, y * scale, (x + window_size[0]) * scale, (y + window_size[1]) * scale]\n","        # print(scaled_box, faces)\n","        ious = [calculate_iou(scaled_box, face) for face in faces]\n","        max_iou = max(ious) if ious else 0\n","        # print(max_iou)\n","\n","        current_box = [x, y, x + window_size[0], y + window_size[1]]\n","        if max_iou >= iou_threshold:\n","            positive_samples.append(current_box)\n","        else:\n","            negative_samples.append(current_box)\n","\n","    return positive_samples, negative_samples\n","\n","# Function to extract features in an image\n","def extract_features(image, box):\n","    # don't include this image if a dimension = 0\n","    # if int(box[3]) == int(box[1]) or int(box[2]) == int(box[0]):\n","    #     return [-1]\n","    cropped_image = image[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n","    # feature_vector = cropped_image.flatten()\n","    # feature_vector = cv2.resize(cropped_image, (16, 16)).flatten()\n","    feature_vector = cv2.resize(cropped_image, (32, 32))\n","    return feature_vector\n","\n","def extract_dataset_features(data):\n","    # Prepare data for classifier\n","    # X, y = [], []\n","    X_pos, X_neg, y_pos, y_neg = [], [], [], []\n","    count_pos = 0\n","    count_neg = 0\n","    scale = 3\n","    for image_path, boxes in data:\n","        image = get_image(image_path, scale)\n","        pos_samples, neg_samples = generate_samples_using_sliding_window(image, boxes, window_size=(32, 32), step_size=4, iou_threshold=0.5, scale=scale)\n","        # print(neg_samples)\n","        for box in pos_samples:\n","            feature = extract_features(image, box)\n","            # if feature[0] == -1:\n","            #     continue\n","            count_pos += 1\n","            X_pos.append(feature)\n","            y_pos.append(1)  # Label for face\n","\n","        for neg_box in neg_samples:\n","            feature = extract_features(image, neg_box)\n","            # if feature[0] == -1:\n","            #     continue\n","            count_neg += 1\n","            X_neg.append(feature)\n","            y_neg.append(0)  # Label for non-face\n","\n","    # standardize the dataset\n","    if count_pos < count_neg:\n","        data_size = count_pos\n","        random_rows = random.sample(range(count_neg), data_size)\n","        X_neg = [X_neg[i] for i in random_rows]\n","        # y_neg = [y_neg[i] for i in random_rows]\n","        y_neg = [0] * data_size\n","    else:\n","        data_size = count_neg\n","        random_rows = random.sample(range(count_pos), data_size)\n","        X_pos = [X_pos[i] for i in random_rows]\n","        # y_pos = [y_pos[i] for i in random_rows]\n","        y_pos = [1] * data_size\n","\n","    # y_pos_np = np.array(data_size * [[0,1]])\n","    # y_neg_np = np.array(data_size * [[1,0]])\n","\n","    X = np.array(X_pos + X_neg)\n","    y = np.array(y_pos + y_neg)\n","    # y = np.concatenate((y_pos_np, y_neg_np))\n","\n","    X, y = shuffle(X, y)\n","\n","    return X, y\n","\n","training_data, testing_data = parse_fddb_dataset('/content/drive/MyDrive/Colab Notebooks/CV_dataset/FDDB-folds')\n","\n","X_train, y_train = extract_dataset_features(training_data)\n","X_test, y_test = extract_dataset_features(testing_data)"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"vFNPFprY9mNj","executionInfo":{"status":"ok","timestamp":1701832569679,"user_tz":360,"elapsed":146,"user":{"displayName":"Jimmy Bao","userId":"13681281117205352536"}}},"outputs":[],"source":["def generate_random_haar_features(num_features):\n","    features = []\n","    for i in range(num_features):\n","        # (x, y) is the position, w = width, h = height\n","        w = np.random.randint(0, 32)\n","        h = np.random.randint(0, 32)\n","        x = np.random.randint(0, 32 - w)\n","        y = np.random.randint(0, 32 - h)\n","        features.append((w, h, x, y))\n","    return np.array(features)\n","\n","def compute_integral_image(image):\n","    # grayscale image\n","    grayscale = cv2.cvtColor(image.reshape(32, 32, 3), cv2.COLOR_RGB2GRAY)\n","\n","    integral_image = cv2.integral(grayscale)\n","\n","    return integral_image\n","\n","def apply_haar_features(integral_image, features):\n","    feature_values = []\n","    for feature in features:\n","        w, h, x, y = feature\n","        white_rectangle = integral_image[y + h, x + w // 2] - integral_image[y, x + w // 2] - integral_image[y + h, x] + integral_image[y, x]\n","        black_rectangle = integral_image[y + h, x + w] - integral_image[y + h, x + w // 2] - integral_image[y, x + w] + integral_image[y, x + w // 2]\n","        feature_values.append(white_rectangle - black_rectangle)\n","\n","    return np.array(feature_values)"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"6rjsT7xl0Xd6","executionInfo":{"status":"ok","timestamp":1701832419448,"user_tz":360,"elapsed":141,"user":{"displayName":"Jimmy Bao","userId":"13681281117205352536"}}},"outputs":[],"source":["# train Adaboost classifiers for each class (one-versus-all)\n","# this uses the weak feature computation (haar features)\n","def adaboost_train(X_train, y_train, num_features, class_label, T):\n","    y_train_binary = (y_train == class_label)\n","\n","    weak_classifiers = []\n","\n","    # initialize weights based on y_i = 0 or 1\n","    weights = np.where(y_train == 0, 1.0 / (2 * np.sum(y_train_binary == 0)), 1.0 / (2 * np.sum(y_train_binary == 1)))\n","\n","    # for t = 1...T\n","    for t in range(T):\n","        # normalize the weights\n","        weights = weights / np.sum(weights)\n","\n","        # train a classifier for each feature\n","        min_error = float('inf')\n","        best_feature_index = 1\n","        best_threshold = 1\n","        for j in range(num_features):\n","            features = X_train[:, j]\n","            threshold = np.random.uniform(min(features), max(features))\n","            predictions = np.where(features >= threshold, 1, 0)\n","\n","            error = np.sum(weights * abs(predictions - y_train_binary))\n","\n","            if error < min_error:\n","                min_error = error\n","                best_feature_index = j\n","                # choose best classifier with lowest error\n","                best_threshold = threshold\n","\n","        if min_error == float('inf'):\n","            continue\n","\n","        if min_error == 0:\n","            break\n","\n","        beta = (1 - min_error) / min_error\n","        alpha = np.log(1 / beta)\n","\n","        # update the weights\n","        predictions = np.where(X_train[:, best_feature_index] >= best_threshold, 1, 0)\n","        weights *= np.power(beta, 1 - abs(predictions - y_train_binary))\n","\n","        # add to full array of classifiers\n","        weak_classifiers.append([alpha, best_threshold, best_feature_index])\n","\n","    return weak_classifiers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-ubWTNNe0VGn"},"outputs":[],"source":["# multi-class image classifier combining one-versus-all classifiers\n","def train_multiclass_adaboost(X_train, y_train, T):\n","    num_samples, num_features = X_train.shape\n","\n","    classes = np.unique(y_train)\n","    num_classes = len(classes)\n","\n","    classifiers_list = []\n","\n","    for i in range(num_classes):\n","        # Train one-versus-all classifier for each class\n","        classifiers_list.append(adaboost_train(X_train, y_train, num_features, classes[i], T))\n","\n","    return classifiers_list"]},{"cell_type":"code","execution_count":39,"metadata":{"id":"PvoBbmnA0PCH","executionInfo":{"status":"ok","timestamp":1701841179083,"user_tz":360,"elapsed":138,"user":{"displayName":"Jimmy Bao","userId":"13681281117205352536"}}},"outputs":[],"source":["def adaboost_predict(X_test, classifiers_list):\n","    num_samples, num_features = X_test.shape\n","\n","    predictions = np.zeros((num_samples, len(classifiers_list)))\n","\n","    for i, classifier in enumerate(classifiers_list):\n","        current_scores = np.zeros(num_samples)\n","        # calculate scores for each classifier in classifier list\n","        for alpha, threshold, feature_index in classifier:\n","            weak_predictions = X_test[:, feature_index] >= threshold\n","            current_scores += alpha * weak_predictions\n","        predictions[:, i] = current_scores\n","\n","    # return the class with the highest score\n","    return np.argmax(predictions, axis=1)"]},{"cell_type":"code","execution_count":26,"metadata":{"id":"QAOLaTs19xv-","executionInfo":{"status":"ok","timestamp":1701834265414,"user_tz":360,"elapsed":379930,"user":{"displayName":"Jimmy Bao","userId":"13681281117205352536"}}},"outputs":[],"source":["features = generate_random_haar_features(1000)\n","X_train_integral_images = [compute_integral_image(image) for image in X_train]\n","X_test_integral_images = [compute_integral_image(image) for image in X_test]\n","\n","X_train_haar = np.array([apply_haar_features(image, features) for image in X_train_integral_images])\n","X_test_haar = np.array([apply_haar_features(image, features) for image in X_test_integral_images])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oB_v8xnjzunX"},"outputs":[],"source":["start_time = time.time()\n","adaboost_classifier_list = train_multiclass_adaboost(X_train_haar, y_train, 1)\n","training_time = time.time() - start_time\n","print(f\"Training completed in {training_time:.2f} seconds.\")\n","\n","# Calculate accuracy\n","predictions = adaboost_predict(X_test_haar, adaboost_classifier_list)\n","predictions = [0 if x == 1 else 1 for x in predictions]\n","accuracy = accuracy_score(y_test, predictions)\n","print(\"Accuracy:\", accuracy)\n","\n","precision, recall, _ = precision_recall_curve(y_test, predictions)\n","\n","# Plotting the Precision-Recall curve\n","plt.figure(figsize=(8, 6))\n","plt.plot(recall, precision, marker='.', label='Adaboost')\n","plt.xlabel('Recall')\n","plt.ylabel('Precision')\n","plt.title('Precision-Recall curve')\n","plt.legend()\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyPXZbrQH8R7t2If6KBFQNur"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}